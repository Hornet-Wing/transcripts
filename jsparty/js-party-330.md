**Kevin Ball:** Hello, JS Party people, and welcome to another episode of JS Party, your favorite/my favorite show about JavaScript and the web. I'm Kball, I'm your host and emcee today, and I am joined by three representatives of the Ember.js core team. We're gonna get their take on all the hottest stuff in JavaScript, how is Ember approaching this. Let me introduce, first off, Chris Manson. Chris, thanks for joining us.

**Chris Manson:** Hey. Yeah, great to be here.

**Kevin Ball:** Excited to have you on the show. Also, another Chris, Chris Thoburn.

**Chris Thoburn:** Hello. How are you?

**Kevin Ball:** Yes, doing well. And finally, Ed Faulkner.

**Edward Faulkner:** Yes. Hello. Glad to be here.

**Kevin Ball:** Cool! So let's maybe start -- do you guys want to introduce yourselves? We can go in the order that I introduced you, share a little bit about your backgrounds and your role on the Ember core team...

**Chris Manson:** Yeah, sounds good. I have been doing Ember for essentially - is it 12 years now? I started in 2011. So that's a long time to be doing a single framework. I haven't been on the core team for all that time. It was, I think, four years ago I joined the learning team, and now I'm on the tooling team, helping build a thing called Embroider, which is the ultimate goal to get Ember building with Vite... But maybe we'll talk about that a bit later.

**Chris Thoburn:** I'm Chris, and I've been working with Ember, I think since 2012, 2013. Roughly around then. I got my start, just liked it as a framework compared to the other options at the time, and I was trying to build a bunch of mobile apps... And I think a lot of my early contributions were all in that space, of building things optimized for mobile. And then over time I somehow got snookered into joining the data team, and now I've been on the data team for seven, eight years, something like that.

**Edward Faulkner:** Yeah. And hi, I'm Ed. I've been, like these guys, around a long time. We're a community with a lot of longevity, which is part of what's unique and fun about it. Something I've enjoyed a lot is, as many of us have gone through multiple rounds of jobs over the course of that long, we're all still teams working together. Even though people's day jobs changed, we've had several groups of people that we've worked with a long time, which is really nice to have that continuity in a project.

I got started because I was running a startup, I was the only technical person, and building a very ambitious app in the medical records space. This is around 2010, 2011. And I could see, as I was trying to build out a pretty complicated app in browsers, that I was firstly noticing I needed to build frameworky kind of things for myself, and was beginning to grow a framework out of my app. And nothing out there really did what I wanted it to do at that point, which is why I was growing one. But growing your own is really -- I could tell it was a bad idea, especially as a single technical co-founder.

So that was around the time Ember as a project was getting off the ground, and it was still very new and rough and full of bugs and stuff, because it was brand new... But I could see that they were trying to build the same thing I was trying to build, so that's how I got involved. At first really just as a user, but getting in at that era of a project just to be a user, you become a contributor, because you're finding bugs, you're fixing bugs...

I would kind of go work on my project for several months, and then I would decide to go take an upgrade of Ember and find a ton of things that broke, because it was new and bleeding edge. And so I'd go fix a bunch of things, send a bunch of PRs in, and then go head-down on my app again for six months.

I eventually went to a conference, the first Ember Camp, San Francisco, and I kind of talked to some people and they were like "Wait a second, you're that guy who like every few months sends us a flurry of PRs, which we really appreciate, they're great, and then you disappear. We've found you. You've gotta come join us." And I was like "No, way I have time for that. I'm not doing open source. I'm trying to run a startup." But after a couple iterations of that, I realized I was kind of doing that work anyway, and did get sucked in. So that's the start of it.

**Kevin Ball:** That's fun. I think this longevity thing is maybe an interesting thing to talk about briefly... So you mentioned -- Ember was one of the first of the sort of modern generation of SAP frameworks, if I recall correctly. What do you think has led to it sticking around?

**Chris Thoburn:** I think it's like I had said at the beginning, it's stability without stagnation. I think we've had that philosophy all along. Sometimes that means that we might take a little bit longer to adopt something, but we are going to constantly evolve, constantly adopt what we see as good patterns, or go try to build good patterns if we don't see a pattern existing.

**Edward Faulkner:** Yeah, I think it comes down to -- part of why I like being in the community is that we've found a bunch of people who kind of agree about the high-level vision about how you should think about software, how you should think of a software teams... And all of that stuff, that meta level stuff about process, about philosophy - if you agree on that stuff, it matters way more than what your exact lines of code say at any point in time... Because your exact lines of code, the exact technology at one moment in time is a snapshot... And it's all going to be different. If you're healthy, it's all going to be different two or three years down the line, and it's different than it was two years before.

\[06:23\] So the constant is actually not the specifics of the code, of the technology, it's the philosophy of the people doing it, like how do they think about software, do they agree they have the same goals as you? Do they make the same trade-offs? Do you think about it the same? So to me, that kind of durable consensus is a valuable thing when you find it, and that's what I attribute a lot of the longevity to.

**Chris Thoburn:** I also think there's a bit on the technical side, where from the beginning, even when it was extra ugly and extra warts, the philosophy has been to kind of build into where we would like to see the language and ecosystem go, and go make the platform and language-level investments to improve it over time. So early class system in Ember, get classes in, early reactivity system in Ember, get signals in. I think these are actually common threads that we've repeated over and over again over the course of the framework's life.

**Kevin Ball:** Yeah. Well, and I feel like y'all have often been on the cutting edge of stuff that then gets adopted later. So like that stability without stagnation reminds me of where Angular has now ended up down the road, after they made some stability missteps, and they learned from it, but then they also had that model and could go with it.

**Edward Faulkner:** For sure. None of us will claim we've never made a stability misstep either. It's a hard problem, and we've gotten a lot better at it over the years. But for sure.

**Chris Manson:** I think there's an interesting point though to add to something that Ed said. If you generate an Ember app - and even that, we have generators; it's something that we've always had. If you generate an Ember app now, and look at one two years ago, it's very different... How you generate components, how things look... It's actually quite different. But even though we have these snapshots, we don't leave people behind. We put a lot of thought into upgrading concepts, upgrading the way to think about an Ember app... And we also put a lot of work into code mods, and deprecations, and linting rules, and all these sort of things to kind of nudge the community as a whole forward, and this concept of not leaving people behind is particularly evident in the Embroider stuff that I was mentioning before. We have a very, very long support matrix. We go back lots of LTS versions - again, another concept to help with stability - to versions that were released... When was 3.28 released? Three years ago? It was a long time ago.

**Kevin Ball:** That's an era in JavaScript.

**Chris Manson:** Exactly. You could rewrite your app twice with something like that. But we still support that, because we know we want people who built their app, got stuck on 3.28 for whatever reason... We want them to use the new stuff and get off the old way of doing things and start using modern tooling.

**Kevin Ball:** And not have to do what Ed did, of write a whole bunch of pull requests to make it work?

**Edward Faulkner:** Yeah, exactly.

**Chris Manson:** Yes, exactly. \[laughs\]

**Chris Thoburn:** That was all pre 1.0 stuff. Yeah, for sure.

**Chris Manson:** Yeah.

**Kevin Ball:** Well, let's dive into some of those specifics then, maybe. So one thing that y'all mentioned was reactivity... And you sort of mentioned that you were looking where you wanted things to go, and now things are going... Can you share a little bit about Ember's take on reactivity? What does that look like, and how does it compare to what else is out there in the ecosystem?

**Edward Faulkner:** \[09:50\] Sure, yeah. So at a very high level right now, I would describe Ember's reactivity system as a kind of -- it prioritizes allowing you to do normal idiomatic JavaScript paradigms for your data reading and writing. So as an example, try to see if there's any piece of state that the reactive system is going to react to. So if it's changed, it's going to necessarily schedule the right kind of validations rerenders down the timeline. And tristate is just like all normal JavaScript state; you don't have to go through a special API to read it or write it. It's a regular piece of state in JavaScript, it's a regular property on an object... And all you've done is annotate it with a decorator to say "This needs to be tracked." And it's supposed to behave exactly 100% the same API, whether it was tracked or not. The tracked is just what opts it into being observed.

So that's a nice property of the system. There's different trade-off -you can make with that kind of choice. But with that trade-off made, it means you are writing idiomatic JavaScript for how you read and write the state, and the implementation is doing -- so the burden on the programmer is to know what the routes of state are. Where do you actually store the routes of state, as opposed to the derived state. Because you want to annotate those things, so that when this thing changes, that's what causes all the changes downstream.

And your derived state downstream doesn't have to know anything about tracking. No matter how deep your stack is, when you call some function that calls some function that accesses a getter that calls another function that eventually hits tracked state, everything down the line is still going to be fine. It all composes out with JavaScript.

So that's a high-level description of what it is and how it works now. So that's the set of affordances we have. The relation to signals is just like -- signals is nice, because it's trying to codify patterns that I think Ember, but also many other frameworks have begun to coalesce around... And it particularly helps with the interoperability issues, which I really think reactivity is the hard piece of interoperability, across all the JS ecosystem things.

Rendering system interoperability is not that hard. Like, you can usually throw it together in a basic version very easily to render a component from Svelte and Ember, or React and Vue, or whatever. Getting the render to happen is not that hard. Getting the reactivity to actually run in a way that's optimal, and keeps the whole app running is the harder piece. So signals is cool for that reason. It wouldn't affect anything about what an Ember developer or a Vue developer would say in their code, but the framework authors would be using signals underneath to make sure that they interoperate.

**Chris Thoburn:** Yeah, I think to put it in some terms that the broader ecosystem will probably identify a bit with - tracked is signals, for all intents and purposes. From a conceptual paradigm, tracked and signals are roughly the same. From the ergonomics perspective, our approach to it has under the hood been very similar to how you see the implementations work in other ecosystems... But the DX of how the average app developer uses it is different. And that's because if you're using signals outside of the Ember ecosystem, you need something to store the signal that you interact with; it's that little box that you peek into and pull out of to get the value, right? That little reactivity wrapper. Well, in Ember we didn't decide that classes were bad. In fact, we still quite strongly feel that classes are good, but they need to be used appropriately. We don't want to see a lot of inheritance, we don't want to see a lot of subclassing... We don't really like mixin patterns... We're trying to push people away from all those. But fundamentally, a class is still just a state container. It's a very useful state container. And when you have that state container, it's very easy to go and say "Well, I have a couple of fields on this state container, and now I want those particular fields to be reactive, so I'm just gonna put a decorator right here. This is a reactive field now." So that's what tracked is. Tracked is a decorator; it just goes on any field and says "You're reactive." I think it actually offers really elegant DX, because to Ed's point of it just being normal, idiomatic JavaScript, it doesn't feel like you're changing the way that you write your code. You wrote your code the same way, and then you decided something needed to be reactive, and you just said "Okay, this is reactive now."

**Kevin Ball:** \[14:08\] Right. And you have a place to stash all that state, which is your class, and you can just use observers on the properties to do the hooks... Or how does that end up working?

**Edward Faulkner:** Yeah. You mean getters, but yeah.

**Kevin Ball:** Yeah.

**Edward Faulkner:** Yes, so under the hood you would see essentially a -- if you're familiar with the accessor decorator... It's part of the spec that is now in stage three. It's a good example of the -- the space of things you need at the low level to implement tracked. Yes.

**Chris Manson:** Just to give you a bit of history, Kball... The reason why you saw everybody in the room wince when you said observer is because we've been in this for so long... There was an Ember concept in the old class thing called observers, where nobody would be getting that value, they'd just be doing work in response to tracked behavior. And it was very hairy, and it made really awful spaghetti code... And we've moved away from it. And it's a concept that grew in Ember, and then has had time to die away, and we've got other things replacing it. But it's essentially a bad word in an Ember --

**Kevin Ball:** Well, I misspoke, because it wasn't precise either... But yeah, I've managed to step into that pile.

**Chris Thoburn:** You did, but I think there's an interesting point there around where a lot of folks in or tangential still to the Ember ecosystem have a difference of philosophy when it comes to the TC39 signals proposal, and what's needed of it, than many of the other ecosystems do. You see some push from other ecosystems to add effects into the proposal, for instance. Most of the people in the Ember ecosystem have zero interest in adding effects to the ecosystem, because they are roughly speaking observers. And we don't really want to go back that way.

I think that opens up a really interesting set of conversations. I've had some really great conversations with folks who do want effects, around third-party interop and syncing data into external sources that are non-reactive using effects... But when it comes down to the general rendering paradigm, we have a heavy preference for everything being derived. And so when you're in this derived paradigm, you just don't need effects. So I think that's -- if you want to dive in more there, we can...

**Kevin Ball:** Well, it gets a little bit too -- so when you have everything being derived, it lets you in some ways think about things more declaratively, and you just kind of like lay these things out over time. Whereas effects are fundamentally an imperative idea, of like "Go and do this thing now."

**Edward Faulkner:** Exactly. And that is really one of the -- it's a really key skill in all programming, but it comes up a lot in JavaScript and rendering frameworks... People very often instinctively want -- when you're looking at one thing in isolation, and you're just like "When that changes, I want this thing to happen", you're thinking imperatively. And so people reach for an imperative tool and ask for an imperative tool. But that has bad scaling properties when apps get big, and teams get big. And so that's where you have to really -- sometimes there's a learning process where you want to help newer teammates, or help new people in a framework ecosystem... Like, pause and ask yourself why you want -- and it is natural to reach for an imperative tool, but a lot of times you shouldn't, right? And there's a few places where you need it, but you often don't. And this is a perfect example of that.

So at a global scale, I think there's a really clear way to see why imperative patterns have problems. It's basically like, you really want to be able to work in the local. You're working on one feature, you want to think about your one feature, you don't want to have to know about all the possible passive dataflow going in and out of that around the entire application, which could be really big... And by splitting effects, or like observability and derived things, essentially splitting "What is my data that I get in, and what are my actions that go out?", if you kind of can bisect that whole space into two kinds of things...

\[18:10\] In Ember we would talk about data coming down to your component, and actions going up out of your component. Like, to the computer, those are kind of the same; it doesn't really matter whether you're observing a change or you're running a function. But in our heads as programmers, as long as we have two categories of things, we can have rules now, like local rules. As long as data changes never cause actions, but actions can cause data changes, they can't loop anymore. You kill the cycle of possibility. You can write a little mathematical proof that you can't accidentally make a global cycle if you cut off one of those possibilities.

An action can change data, but data changing never fires in action, so therefore you will never loop... And that kind of thinking in the small, and making sure that the global thing actually works out good is something that an app developer should almost never have to reason about if the frameworks have done it well... But it's the stuff we have to stress about as language contributors or framework authors.

So an idea -- not to resteer us, but maybe to throw on your pile... When Chris brought up -- well, Chris Thoburn brought up one of our longevity things about standardizing things into the language, I think there's something to that... It gets back to what I said about having the same kind of philosophy of what a framework is for... Because we really see what we're doing as framework authors as language extension, as building a language... And everything you're doing when you're making a framework, or even like a very sophisticated library, you are really crafting a new language, or at least a new dialect of a language. And if you think like a language designer, you're going to make different choices than somebody who's just thinking as an implementer of like "I wanted this subsystem of my app to be shared with other people."

**Break**: \[19:57\]

**Kevin Ball:** So this does go in a direction that I think is really interesting. It's one I love to explore, which is around -- I mean, when you say creating a language, you're creating a domain-specific language. And this takes me into something that I think, Chris Manson, is in your domain around Embroider, because I think one of the powerful things about owning your own build system and your build step is that you can create parts of that language that maybe don't exist in the underlying language. And a very common example people are very familiar with right now is JSX. JSX is a domain-specific language for creating HTML from JavaScript, and it is not in and of itself JavaScript; it is syntactic sugar. They love to say "Oh, it's really just pure JavaScript underneath it." It is semantically JavaScript, but token-wise it is not JavaScript. And that's fine, because we have access to a build step. We can say, okay, like, have a compilation step that compiles this to JavaScript. Is that part of what you do with Embroider? Are you extending the JavaScript language to have Ember-specific pieces? And how does that end up working?

**Chris Manson:** So I want to just correct the record on one particular thing... Yes, okay, I'm only really here to talk about Embroider stuff, but Ed actually invented Embroider, so he knows more about Embroider than I do. It just happens to be my day job at the moment, because I have the very fortunate opportunity to work on a thing called the Embroider Initiative, so I get to do it all day long every day, which is very cool.

**Edward Faulkner:** And I have thoughts, but I don't work on Embroider. \[laughter\]

**Kevin Ball:** Well, this is not closed to anyone, but I did want to throw it to Chris, because that was his sort of day job specialty right now.

**Chris Manson:** Well, I'll give you my perspective, and then it can correct the record once I get something wrong... But the way that I see Embroider is that actually we're not necessarily owning our own build step here. The main thrust of everything that we've been doing recently is to try and get Ember working with Vite. Because Vite is the new hotness, everything has to work with Vite, and it gives you a certain amount of hype to be able to say "Oh, look, Ember works with Vite now." But the work that we're doing an Embroider is not going from characters in your editor all the way to the browser. It's converting what we call Ember-isms, so the things that only exist in the Ember ecosystem, to essentially standards... But we only need to go as far as what Vite can understand.

The best example - and you were talking about JSX; we have a template format in Ember... The best example recently has been Ed's work on a thing called content tag. So we have an RFC process in Ember, and Ed wrote this RFC that describes how to essentially just put what looks like HTML inside somewhere in JavaScript. But the thing I like the most about it is it wasn't specifically worded for Ember. It was worded as if that RFC could be copy and pasted, and sent straight to TC39. And that's why it's called content tag and not template tag. We use the template version of it, which is the specific implementation of the generic idea, that you can convert a bit of domain-specific language into something else that works inside the context of a JavaScript class, or otherwise.

**Chris Thoburn:** Yeah, it is one of the things I'm really excited about, where I'm like "This is, again, Ember coming in with an idea that I would love to see brought into the ecosystem, and really into the language as a whole." I've started a few conversations with different players around that. I think there's a ton of utility there. And my love for it is actually not even from the Ember side of things, it's from the data side of things. I think GraphQL tooling showed us that hey, having nice syntactical language embedded straight into your code... Syntax highlighting, autocomplete, linting, all of that is nice. How do you actually get that language into your JavaScript in a fully supported way? I think content tag is actually a nicer approach to that than some of the backtick approaches we've used to this point.

\[30:17\] And I've been developing a proposal within Warp Drive, which for this conversation maybe it's easier to keep it as Ember Data, but we're rebranding to Warp Drive as we go universal for all frameworks. But I have a proposal I've been drafting for that, that essentially is content tag, but specific for how do you write a query against an arbitrary REST endpoint in a way that's expressive, where if we had a spec for your endpoint, we could validate it against that? To give you that end to end type completion and end to end robustness that we like out of ideas like tRPC, and we like out of ideas like GraphQL, but for the rest of us; for everybody else that just has an arbitrary REST API they want to hit.

**Edward Faulkner:** Yeah, I can give like a little more filling and a little more what people are \[unintelligible 00:31:06.10\] Think of it as -- it's essentially the proposal that what if JavaScript had the ability to have little blocks of other arbitrary languages embedded in a nice way, where you have nice tooling around it, and a nice place for whatever DSL you're embedding, that could just be a nice place to put some CSS in your JavaScript, it could be a nice place to put a templating language, it could be a GraphQL query... Whichever those are.

At a very first glance, you may look at it and say "Smells JSX-ish", but it's very different semantics. It's not everywhere in the language; there's certain places. And it's deliberately keeping your inner language and the JavaScript having to try to have a firm boundary between them. It's not arbitrary control flow in these places the same way that JSX would be.

So it's basically trying to give you a sweet spot that you don't get without it. And we did debate heavily within the design process and within the community about the value of -- like, it's a big step to decide to go in and do a syntactic extension, right? There's a lot of tooling required. You had to go on a quest to get enough projects using the extension that GitHub would have a high enough count, so that we could get the syntax highlighter into GitHub for the new file extension... There's a lot of steps when you go and extend the syntax. So it's not something to do lightly. It is something to do thinking like a language designer, hoping to get it into the language, or at least make it popular enough like a JSX, which is, again, not in the language, but popular enough that tools feel like they have to support it.

So we just we struggled hard whether we wanted it, but the trade-off of what you get for it is like a sweet spot where you really can use it as arbitrary expressions, composing all throughout your JavaScript; you get the niceties of like a single-file component format, but then you can still put it wherever. You can still have many of them in a file, you can -- you have the niceties of single-file components, you've got a templating language that's fine-tuned for your rendering alongside your JavaScript in a very tight bundle... But it's still embeddable in arbitrary JavaScript. That's really why we thought it was worth doing that syntactic extension.

So that's part of an answer to your question about what are we getting for extending the language... And you brought it up in the context of owning your own build system... So that's where we can kind of set the description of what is Embroider, and what is Ember trying to do with our build system. A question that came up when you were sending questions before the call was "Why have your own build system?" The answer is really we have one because it was a radical thing to do to have a build system when we made ours. People thought the idea of a build system was absurd, and we said "No, we can do this. It's going to give you a lot of power you didn't otherwise have." And we did it, and it was quite radical as a community to say -- even for us, there was a time when it was like an optional thing to have a build system. But eventually we said "Look, no, there's just too many features that need. It is now mandatory. Everybody's got a build system." And that served us well for a long, long time.

\[34:12\] So to some extent, that build system is the victim of its own success, because it was early, and it's been heavily used, and it has extremely powerful affordances for third party packages to come in and do sophisticated things for your app. So people really loved that you could write Ember add-ons that with a single -- like, install the package, and it sets up everything for you, and it's all built into the build system.

That was all very nice, but because it was so -- it had such powerful affordances for third party code, now you're very locked into that build system. And it is a build system that is older than ES Modules as a spec, it has a lot of cruft in it... And so Embroider is a project to create a migration path to get that whole ecosystem moving together onto more standardized build tooling that has emerged since then. So we don't want to necessarily worry about owning the whole build pipeline. That is not a thing. That's not the unique selling proposition for Ember. We want to have a great DX for developers, we want to have a strong community of people thinking the same way about building ambitious applications... Like, how do you ship your JavaScript modules and split them is a thing that shouldn't be unique; I don't think it has to be unique for Ember apps. So we would love to be on standardized tooling for that, and have a much thinner layer of the custom stuff. So the things we talked about with content tag and template tag - that should be a nicely-documented, pretty thin plugin that you could drop into Vite, or drop into ESBuild, or whatever, and not have to own the whole thing. So when we talk about Embroider, we're mostly talking about the process of moving a very large community of add-ons and apps over that hump, and getting them off the older customized thing.

**Kevin Ball:** Yeah, that makes sense. Well, and it's interesting, because the rise of that tooling layer of things like Vite, and before that WebPack, and Rollup, and Parcel - and there is a whole ecosystem around this now - in my mind should be pushing people to more of this, like, "Okay, we have all these tools. What can we build on top of it that's actually useful?" And we see some interesting innovation in frameworks like Qwik, where they say "Hey, you know what? We're going to build a language extension which allows us to infer where the boundary is between server side and client side, and hand things off more nicely. Because you opt into a little bit more constraint, you tell us something explicit, and because we have control of the build system", built on top of, I believe, Vite, "we can do some transformations and make that just work."

**Chris Thoburn:** I'd say Embroider's kind of two things right now, which is -- I'd like us to actually rebrand Embroider in the next like year or two, because I think people are going to end up conflating Embroider with the migration, instead of Embroider with the end goal... And once we get closer to that end goal, it should probably honestly just be called Ember.

**Edward Faulkner:** Oh, yeah.

**Chris Thoburn:** Those two competing things are, in the early days I was mentioning we had to convince people they needed a build tool, we had to convince people that this was a \[unintelligible 00:37:13.12\] tool to even use, and we had to build the build tool. Build tools now exist; we don't need to build the build tool. Everybody kind of understands where the value build tools are; we don't need to convince them that there's value in a build tool now.

So I really look at Embroider as us pivoting towards almost the Remix approach. We're just a build plugin. It doesn't matter anymore. If it's RSpec, or WebPack, or Vite... We're just a build plugin that you put over the top, that handles all the framework-specific concerns. And I think that that's a really powerful paradigm, because not only does it mean there's a lot less work on the tooling front for us as a team to have to care about, because we would like to focus on great DX in the framework, but it also means that it's easier for us to just be a part of the broader ecosystem, be a part of the broader platform, and allow things that have become good conventions to just be good conventions.

**Chris Manson:** \[38:03\] And there's a really interesting idea here as well if you think of Embroider as just a migration path. There was a member of the community, the Ember community that created Ember for Vite. It must have been like two years ago now, I can't remember, but it was essentially having Ember building with Vite, and it was great. It worked. But no add-ons worked. So no app could ever use this, because it was essentially handwriting everything. So it was just JavaScript and a few plugins, and stuff. But that's not good enough for the Ember community. The whole point is that you can upgrade your app from -- there are legitimately people that I've been working with in the Embroider Initiative that have an Ember app that has served them for 10 years, and they are a billion-dollar company. And that is the truth, that's what we have. And we don't want them to say "Oh, by the way, you now have to rewrite your app from scratch in Ember again, but with this new Vite build tool." And if we wanted to say that, we could have had Vite two years ago, but it wasn't good enough.

So when we've been designing this, a lot of the pieces that look at your app and convert Emberisms into newer things are like virtual imports, or pieces that you could, in the future, when they're not needed, technically just delete that line. And then as you have less and less of the old stuff, you could just look forward and it looks like a normal JavaScript app with "Oh, look, there's a bit of content tag." That's the little piece that's interesting.

**Edward Faulkner:** Yeah, if you want, I can get into some of the specific technical things that could be interesting about builds... Just to throw one out and see if that's something we want to go into and provide just a little depth... I mentioned how add-ons were very, very powerful in our original build system paradigm... Too much so, in the sense that they could just drop an arbitrary file as if it existed in your app anywhere they wanted. And so when you think about what that means, to get something to build, we have a resolver plugin that's gotta go into something like Vite. We have it for Vite, we have it for Rollup, we have it for WebPack... But when you encounter some import for like ./mycomponent. That doesn't just mean that file, it means look at the database of all the add-ons who might have dropped a file there... And it's a very weird thing to do. And so when you look at something like Vite's \[unintelligible 00:40:31.14\] it's never gonna think that might be coming from some add-on. "It's clearly app code. It starts with a dot. Move on." And that just doesn't work.

So that's what I mean when I say we had an overly powerful bunch of capabilities in the add-on ecosystem before this, that makes us -- that's why we have to build tooling to help people with this process. So we want to give you tools to solve all that in a programmatic way, so that you can get an app across this without having to handrewrite the world.

**Chris Thoburn:** I think the interesting thing there is there is a subset of those capabilities that add-ons then had, around "Oh, I'm going to get built by the consuming application. That means I can utilize configuration from the consuming app to affect how I get built." That was both really powerful, and something that the broader ecosystem took forever to figure out they even wanted.

So we call these macros, the broader ecosystem also now is starting to bring in macros in lots of different frameworks... Most of the macros today are just like "Am I the production env, versus the dev env?" And we go quite a lot deeper than that as to what can be allowed there. And the really awesome thing that Ed did, really close to the start of the Embroider initiative was going to say "Okay, we need to formalize the kinds of things that a library that's getting consumed might want to do based on configuration from a consuming app, and find a way that that's actually going to work well." And so now it's just a Babel plugin. It's a Babel plugin that we -- there's a little bit of entanglement, but probably we're pretty close to being able to use that even without an Ember ecosystem... Just add this Babel plugin while you're compiling this set of assets, give it the config \[unintelligible 00:42:15.02\]

\[42:19\] And that concept of macros - that was one of the challenging things for us in Ember Data and Warp Drive, because we did a ton of stuff during build based on user config. We will strip all the deprecated code out if you mark it as resolved. If you're in production, we remove a whole lot of nice, helpful developer asserts that tell you "You did this wrong, or you did that wrong." We've got optional feature flags that are managed this way.

For a while we got away from this, but for a while we were managing all our peer dependencies "If you have this peer present, that's an optional peer, then we we'll automatically wire this in for you." We've steered a little bit away from that in favor of explicit wiring... But really kind of powerful, expressive ways of changing the output to give you the most optimal library code that you can get based on how your app was actually going to use it.

So that project of separating out macros is -- one, it was just huge, and I think still we need to do some work to socialize what all is needed there in the broader ecosystem, because I think it has value. And two, that's honestly the reason that we've been able to take Warp Drive and say "Actually, we are gonna go universal", because since it's just a Babel plugin at this point, we're no longer doing anything particularly crazy. Now I can come in and say "Okay, well, if you want to install Warp Drive into your project, then you're going to need to -- in your build pipeline, you just need to configure call set config with a base configuration here, and make sure you have this Babel plugin installed. I love it.

**Break**: \[43:50\]

**Kevin Ball:** There's something interesting here... And what you're talking about in terms of allowing libraries to change the way that they are built based on configuration in the consuming project - in some ways it's another take on this "What are the ways that data flows?", except now it's looking at your build project, or your build part as part of your application... Which is a nice brain shift, a little bit.

I do wonder -- I mean, this reminds me a little bit of the whole shark fin of getting excited about meta programming. Like, you get so excited about the power, and then at some point you get to a place where you're like "Oh, shoot! This is impossible to reason about, because it's too general purpose. I've got to drop way back down and then only use this in very tightly-constrained places or ways."

**Edward Faulkner:** Oh, yeah. Oh, yeah. I like the shark fin description of that. I've always thought of that as like the most dangerous programmers are the intermediate skill programmers. The beginners don't know enough -- they make simple mistakes, that aren't so costly. And the pros have been burned, and they learned. It's that intermediate level, where you're just starting to get the power and it goes to your head. Absolutely.

What you were saying about building systems and bringing them in and changing your thinking about them - it relates to something else I've thought about this, which is that, like, we talked about reactivity... Build systems are also purely -- like, they're a very much a reactivity system problem. And when you look at what's required to make a nice developer experience around build systems, it actually is very similar to the problem of frameworks and their rendering. The build system is rendering an app and wants to do fine-grained invalidation of just enough stuff. They're actually the same kind of paradigm, and you find the same patterns repeating over and over again. It would not surprise me if signals lands in TC39, and like Node implements signals that you could actually make a really nice clean-up of build tooling that's implemented on Node by using signals to inform when this piece of this thing dependent on that, which depended on that, which depended on that; the signal will tell me that that cache isn't valid.

**Kevin Ball:** But do things like macros invalidate that unidirectional flow, because now you have things coming back from your application configuration into different libraries, and then out again?

**Edward Faulkner:** I mean, I don't think it creates a cycle necessarily. It does mean you have to design it well. The thing is with signal -- signals would be the nice primitive to do that. If the whole build system -- like, say a new version of Rollup was built on signals for incremental rebuilds, and you wanted to make your macros work in Rollup. As long as your macro plugin sent a signal about a thing changing, the rest of Rollup would know that it changed.

Think about it this way - if the value coming out of your plugin is a reactive value, and it's following a standard for what reactive means, now rebuilds will be efficient without you having to go and learn some special API about your build of like "Oh, remember to add a watch file here, but you can only do it in this phase." There's a lot of very handcrafted reactivity stuff that keeps incremental rebuilds working... And if you had a way to -- if your plugin actually just proves the value, but the value is reactive via a standard, now you don't need all that stuff.

**Kevin Ball:** Yes. Oh, it's really interesting that you're saying that, because it's reminding me -- I'm drawing the connection between these watch file systems and Angular's old system, which was just basically a watch file system for how it was doing rendering. Yeah, that's fascinating.

**Chris Thoburn:** I really do hope Node \[unintelligible 00:51:24.24\] signals in maybe even before V8 has them exposed, if it gets into the language... There's been a lot of discussion from folks working on that spec of "Does this have value outside of the browser paradigm or not?" And my argument has been "It does for build systems, but I also think it does for ORMs." I've seen so much bad JavaScript server-side code around memo-ization and deduping of work that I think using signals and computed really would clean up quite a lot.

\[52:00\] People don't necessarily think of an API being a reactive framework, but the reality is is it renders the JSON that you return. And a lot of the times to get to that settled state you're gonna run computations on complex cyclical graphs, which means that you need to know which portions of that graph have been validated. And if you're authoring how you build up that payload in a highly asynchronous environment, where it maybe took multiple round trips to your database to assemble the data, calls out to multiple other microservices to assemble the data, that's all getting merged together to get you into that final payload - you actually need something that kind of colors that graph for you and tells you which parts have changed and which parts haven't, and what's invalid.

I actually think there's a whole space to explore there that's really neat, that people have not really started to consider yet... And I've jokingly been thinking "I need to start trolling \[unintelligible 00:52:59.12\] on Twitter repeatedly", until they make an attempt at it just to say they did.

**Kevin Ball:** So I'm gonna guess some of this is informed by what you've been doing with Ember data... Because you're talking about kind of bringing reactivity and change tracking and all of that into managing your data layer. So let's maybe talk about that a little bit. Can you share about what is Ember data/Warp Drive, and how does it work? And how does this reactive paradigm play out there?

**Chris Thoburn:** Chris, did you want to interject first, or...?

**Chris Manson:** No, I just wanted to add one quick thing about what you said about the reactivity on the server side. Like, there was just -- all the things that you were saying about microservices is totally true, but when you're just considering it in terms of a single JSON that's then ultimately responded, it's complicated enough; what if you add web services into that, so that the client was subscribing to that? You now have to keep the colored graph somewhere on the server, and then if something did change, you would send a diff somehow, across a web service. Obviously, this is pseudocode thinking, but... Imagine having to recompute that really complex JSON, and then have to update it without having something signal-based. Like, I'm sure plenty of engineers have attempted something similar in the past, and have tied themselves in knots trying to do it.

**Chris Thoburn:** I just see a lot of really brittle memorization. That's how most people seem to solve it.

**Edward Faulkner:** Yeah. Well, it gets back to what Kevin was talking about too, with the possibility of systems that on their own decide when to spin the server and the client, right? It's that kind of problem. If you had one coherent way to express change across those, your build tool or your framework could in fact decide to split that work on its own. And that has been a dream for a long time, to just have like -- there's been a lot different names for that paradigm, grid computing, or... I'm trying to think -- there's been like many generations of the thought that you write a bunch of code and you don't know where it runs,a nd that's okay, and the system figures it out for you. I've never seen it done at like big scale successfully in JavaScript, but that doesn't mean we can't yet do it. Maybe having the language stabilize more of this stuff would make it plausible, finally.

**Kevin Ball:** Yeah. I mean, I think some of the stuff that Qwik is doing with resumability, and Astro with their islands and stuff, where you have kind of things that are rendered server-side, but then load the right JavaScript when it's needed on the other side, and can pick things up, is as close as I've seen to somebody doing it well.

**Edward Faulkner:** Yes. Yeah, exactly. Exactly.

**Chris Thoburn:** \[55:43\] But "What is Ember data?" or "What is Warp Drive?", I think that's a loaded question, but I'll try to unpack it. I think it helps to understand -- I think Ember data's birthday is SproutCore's birthday. And we don't actually know when that is, but it's sometime in 2006. The very first commit to SproutCore in the Git history is a port from its Subversion repository. And in that commit, you have models, records, record arrays, array proxies... Everything that formed the core of the early Ember data experience in a way to go load these things. And my understanding is that a lot of the way that that was built and designed at the time was as an attempt to bring the idea of core data for iOS, which was also getting built out at that point in time, into JavaScript, so that SproutCore and the Core Data APIs would be very similar for how they were building applications.

So that's where we started - a client-side ORM that is assuming persisted state, except it didn't have persistent state; assuming availability to all the data you would care about, except it didn't actually have access to all the data you cared about... That would just kind of magically sync in the back ground, even though you're in a low-availability, high interruptability paradigm when you're in the browser... And so out of that, as Ember formed out of SproutCore, I think you got this idea "Well, let's separate that portion out into its own library", which is where Ember Data came from. It just got ported out of that codebase at that point in time, split off... "And let's see if we can build kind of a general-purpose client-side ORM, with a bit of a nicer abstraction around the network layer for applications." That's an incredibly hard problem, even if you don't consider the fact that you are now effectively in a remotely-distributed replica that is highly unavailable, and high latency, and always in a partial state, always in an incorrect state... And that was a crazy challenge to try to take on. And I think a lot of folks in the early era hit their head against some of the challenges that come with that, and split off; just decided "We're not going to use this." And I was one of those people. I very early on said "This is crazytown. I'm not gonna use this library." And I started working on all my own stuff... Which I never loved, because trying to build your own fetch abstraction, especially before fetch - it's a hard problem. But you could custom-tailor the difficulty to your app. "What are my app's requirements?" So figure out which portions of that hard problem you need to solve for you, that was enough, and move on.

And then I joined LinkedIn... This is like eight years ago now. And they were using Ember Data, and they're like "We have a lot of problems with it." o I got to work on the library, trying to address some of those problems... And here I am, eight years later, still working on this library... Which has been fun. But the way that I think about it now is very different from its origin. And that really ties into why the rebrand from Ember Data to Warp Drive. Because I think it's time for a clean, cognitive break for a lot of folks who felt the patterns that it had, and knew the patterns that it had, and either loved or hated those patterns.

What it is today is -- at its lowest level, it's managed fetch. And for managed fetch, it basically has the premise that everybody needs managed fetch for various reasons, whether it's better handling of error states, or just authentication, or just a little bit of data normalization, or a little bit of header manipulation, some caching concerns and whatnot. Everybody needs that pipeline, but it's hard to actually go find a library that handles that pipeline well. And a lot of the alternatives out there today that end up getting used end up being very specific to frameworks that they're in, or very -- you can argue TanStack Query is general-purpose, but it's really difficult to use that if you don't have effects.

\[59:57\] You could argue that Apollo is general-purpose, but now you're tied into a very specific backend. There's lots of small managed fetch libraries, but most of them are telling you "Hey, every time you make a request, you can do a whole lot of work, wherever you're making that request, to add what handlers you want for that one specific request", and that's it. Whereas Warp Drive's premise is you set up a pipeline when you're creating your app, and you say "This is the chain of responsibility for how requests get handled", it is a very light decoration over top of the Fetch API, but now you call the request instead of fetch, and you pass in what are fetch options, plus a little bit of extra properties that can do some special things... But you pass in what are fetch options, and it just passes it down the pipeline.

And so now, instead of every time that you make a request each place in your application you need to go and wire all these things together, you just have a thing that's already wired together, and does it. So... Managed fetch. At its core, that's what it is. And that's nonreactive, there's no cache involved by default... It's just managed fetch.

But then you start going "Well, actually, my application needs a cache." We come in with "Okay, well, here is how you plug in a cache handler, and here's the spec for what a cache needs to implement." And this is where the value proposition of Warp Drive really diverges from the rest of what's out there right now. We don't look at how we cache data as a simple HTTP level, request kind of cache; we look at it as "We're going to try to semantically parse your documents into constituent components", so that if multiple requests have responses that have overlapping portions of their data in the response, we understand how to intelligently move those together. That comes with a whole bunch of nice things, because now let's say that you want to replay requests in a different order, it doesn't matter if a later request updated the state of one of the associated things, it's automatically going to be in its latest state.

**Kevin Ball:** That reminds me a lot of how Apollo's caching works, but it's no longer just specific to GraphQL.

**Chris Thoburn:** Yeah. It is very similar. The really big difference between Apollo's caching and Warp Drive's caching is that we're far more efficient at this. I was building -- yesterday I spent my day trying to see how far can I go into the Vite world with a specific set of add-ons, and what's working and what's not... And one of my curiosities was to see if I drop down Warp Drive to just what I want the core experience to be in a year, what's my current size at? Because the project as a whole is a whole bunch of packages, and the default configuration is much larger than what I would actually recommend someone to do if you were kind of wiring it together yourself in the way that we're trying to propose people do in the next year... And my napkin math had been we should be around 18 kilobytes. 18 kilobytes for something that has every feature of Apollo, every feature of TanStack Query and more... Which is a third of the size of either of those libraries. It weighed in at 28. Granted, that was Gzip, not Brotli, but it weighed in at 28. So I'm like "Hm... Maybe this is in my migration support there's a little bit more weight here than I was expecting. I need to go figure out where this 10 kilobytes came from." So I'll probably be doing some optimization. But I really strongly feel that somewhere around 18, 20 kilobytes is going to be the final size for something that handles all of that, but is general purpose.

But yeah, so one of the big differences between Apollo's caching strategy and Warp Drive's caching strategy is that the way that we approach how we handle the identity of data allows us to far more efficiently traverse the graph and update it... Which means that -- you see a lot of folks eject from the normalized cache in Apollo, because it becomes the performance bottleneck. I think that it's going to be exceedingly rare for you to ever choose to eject from the cache using Warp Drive, because the efficiency is just much nicer. And it comes within a more robust dataset. You can't really do cyclical relationships very well in GraphQL, because the concept of identity deep into the graphs is just not really there in the spec. We're set up for cyclical relationships deep into the graph, no matter how deep you want to go out of the box.

\[01:04:25.07\] So really powerful cache, really performant cache... The default implementation is JSON API as a spec, but it is -- there is a cache spec that you can implement. So you'd think that it's too expensive for you to either migrate your API, or do some transformation on the frontend to get into the JSON API format... There's a way for you to implement a cache that can handle all the things it needs to handle, more specific to your format. So nice plug and play there. Still, completely nonreactive. We're still just in -- I'm plain old JavaScript land. No framework-specific, no reactivity.

What we realized about four or five years ago in Warp Drive, a key insight was we didn't want to be tied to Ember's reactivity system. And we realized that because Ember was itself going through a change in its own reactivity system. We had had kind of the classic Ember object computed observer paradigm, going way back, with kind of a couple of variations even within that paradigm, to be honest... And then we were introducing tracked; you know, the more signals-based reactivity approach. You have one that's observer-based, one that's push state-based, one that's pull-based... I'm trying to write a data library that is supposed to work with both of these things... Good luck.

So we realized that we needed to have really tight coordination around the timing and the granularity of updates, and how those updates would broadcast into an associated reactivity system. So I looked at this and I kind of digested what's needed, and I realized "Well, we've got data coming in from remote sources like your API, that is potentially being pushed in by even WebSocket. We've got changes coming in from your application, where you're updating things. And none of these actually play well in a pull-based reactivity system, because anytime that you bring in new data, you actually do have to do work right away. You have to do work right away to figure out what you did, in fact, invalidate, to then go tell the reactivity system you're invalid." So with that in mind, I realized that the paradigm is actually push-push-pull. That's how I would describe it. So we push data into our cache and do work on that first push.

We try to avoid doing work that can be done later, so it's like we're going to do the minimum amount of work in that first push to put the values in the right places, merge them together, and then update a list of what needs to be notified. The second push is now let's go actually notify the reactivity system. So that's a push out to the reactivity system to say "These things are now invalidated." And then the pull is whenever that reactivity system decides to say "Okay, I'm recomputing. I'm gonna pull on some state." And we have intelligent ways of deferring some of the work until the poll, when it's just not required that we do it upfront... But overall, that's how we solve that problem. Which is \[unintelligible 01:07:18.08\] why when it comes to TC39 signals proposal I'm sitting here going "I don't think I need effects." I have built one of the most advanced data libraries out there that's reactive, and we don't actually have a place in here where we need effects for this to work. Because we figured out that, hey, actually, we needed -- even with signals, we needed to go and manage a little bit of bookkeeping still ourselves, and then integrate with the reactivity layer. We don't actually want to build that fully over just reactivity primitives, for lots of different reasons. And so I think it'll be very interesting as that proposal evolves, and as more people start trying to build new libraries over it, who kind of has this realization of where it's good versus where it's bad to integrate it... But I think, because I had to juggle all these different reactivity paradigms in Ember, we had to already do a lot of this thinking and figure out a lot of these integrations...

\[01:08:19.29\] Which is also why we were able to go universal so easily, because now that reactivity integration is already just one small file off in the corner of the thing, and I need to go into and either make it a couple of hooks, so I can plug in a different reactivity system, or just change it over to using the TC39 proposal directly. So really, it's some nice factoring there...

And that leads me to the last piece - where is it actually reactive? Well, after you've set up your cache, if you then decide that "Hey, I want to have a presentation layer in front of that cache", because a lot of times the data you get back from your API isn't quite in the right format for how you actually want to use it in your application. We have a hook where you can implement a thing to instantiate a class; that default is going to be schema-driven. Those schemas can come from anywhere, including from your API. It uses that schema to figure out "Okay, how do I take data from the cache?" and "What am I supposed to transform it into for you?"

It has affordances for derivation, so you can have properties on these record instances that don't exist in your cache data, they just derive new values out of the cache data... All sorts of interesting things like that. But it then becomes --it's a proxy, and then it becomes this intermediate transformer where when you access a property on it, it gives you the nice, hydrated thing that you wanted to work with in your app... Like, let's say for instance \[unintelligible 01:09:36.04\] And then when you set it to a new value, it's going to automatically transform that back into the cache value, so back into a more serialized state, like it would be for your API.

This makes it really easy for us to do diffing of values to give you "Oh, here's the patch you need to make to go save a request to your API." It also means that it's really trivial for us to take that and serialize it into something like IndexDB. So the near future, where I've been putting a lot of work in my free time the last month is the out of the box experience will be that your cache is persisted cross-tab, syncs cross-tab - we'll use a web worker in the background to make all of the actual fetch requests for you. So we'll take the work of doing fetch off the main thread for all apps, we will take the work of updating the cache off main thread for all the apps, we will automatically sync across all your tabs, so you're in the same state, we'll dedupe requests across all the tabs, so you don't end up with thundering herd scenarios if you have a whole lot of tabs open... And we'll replay out of that cache based on your cache policy. So if you were to open up a new tab, you'd just automatically replay out of IndexDB and get into the correct state for whatever requests you make.

**Kevin Ball:** Quick question about -- so in my head, what I'm hearing is like you essentially have a view layer, computed models in front of your raw backend, which is communicating with the backend. Does that view layer - like, can it compose multiple elements from your cache, so you might have like a few different things, but that's not how you want to present it to your application?

**Chris Thoburn:** Yes.

**Kevin Ball:** That's fascinating

**Chris Manson:** Just to add a little bit of color here... Because I always have this feeling when I listen to Chris talking about Ember Data... It's all very complicated, and in ways that I don't really understand. But the best thing about being an Ember developer is that I don't need to understand the layer that Chris is working at. I never have to worry about all this cache stuff. I get this batteries included, app-generated that, you know, I follow the Ember guide, it tells me how to interact with the default setup... And I assume there'll be some default Warp Drive setup when you generate a new app... And I don't have to think at that layer. And it's back to a point that you made earlier as well, Chris, that if you're making this managed fetch thing, you can make it as small or as big as your app needs.

\[01:12:06.18\] But the thing I like about Ember is that you don't know how big your managed fetch needs to be when you generate the app the first time. When you generate it, you've got zero users. Of course you don't need something really complicated. And if you blow up in three months, four months, two years, you might need something really complicated. But if you can use the same tools --

**Chris Thoburn:** But I think this goes all the way back to the opening of the podcast, and what Kevin said... The timescale here of stability and longevity is a really interesting story. A lot of the apps that I've ended up working on are a decade old. I work at AuditBoard right now; we just sold for 3 billion. We've been around for about a decade, maybe 11 years now, all on one Ember codebase. And I think that that's actually a huge secret to the success of a lot of the nice exits that we've seen from these kind of software as a service companies building with Ember, is that they were able to focus on building and shipping product for extremely long timescales without getting caught up in design choice debates and rewrites.

So a lot of the philosophy for me that's gone into "How do I evolve Ember data into Warp Drive?" is "How do I set us up for the next 10 years?" How do I set you up to fall into the pit of success in a way that you can start small, start with what you need, and continue to scale? ...whether it's scale the amount of data you're using, scale the size of the team you have, scale the size of your application codebase? How do you scale across all these different factors, for a decade, so you can get to that point? So much of the design goes into that. And that leads to some really interesting trade-offs, because sometimes it means that the ergonomics of the simplest fetch case seem a little bit overbearing. You're like "Well, why did you do it this way, Chris? This seems a little bit more verbose than it needed to be." And it's like "Well, it is slightly more verbose upfront." But when you start bringing in all the other pieces, and you start going a lot like "Now my app needs this. And now my app needs this. And now my app needs this", they will very naturally extend into this. And instead of you getting into the problem where like "Oh, now I need to go redesign everything, because it turns out that this API wasn't sufficient enough for all these other use cases I'm now thinking of", it just kind of naturally scales and works.

**Edward Faulkner:** Yeah. That kind of thing has always been -- and not just on the Ember Data side, but that has always been part of the struggle of both the good and the bad of the JavaScript ecosystem. Part of the good is that it continues to expand. It's always dominated by new developers, because it's like doubling every so often... So stick around long enough and you will be in the minority of people who've been around a long time. There's a constant influx of new people who don't have all the history. That's great. It's there because it's like one of the most accessible programming communities that people get started and launch their careers in, and I'm fully on board with that. It's why we also care a lot about trying to have good learning materials, and be a community that has tools for developers along the whole continuum of their career. But at the same time, it does mean that -- people don't know what they need yet when they're just getting started on an application. And you know that if you're actually successful with this app, and people are still working on it two years from now, there's things you're going to wish you did right. But those things are not obvious in the beginning. And so it doesn't really work as a marketing strategy to tell people "You've got to just eat your veggies. Do the right thing from the beginning", right? You have to try to find really clever ways to bend the curve, where you can scale gradually with them. But it's a hard pitch to make day one.

\[01:15:50.29\] Or like when people are comparing toy examples of frameworks. It's very easy to come out with misleading conclusions. We know the reality of working in a real codebase -- you don't need to be a 10-year-old codebase to have these problems. By the time you're a year in, if you have a lot of developers, you can be in a massive disaster if you optimized for the toy situation. But at the same time, it has to actually be fun to kick off a new app in it. It shouldn't suck, right? We're not trying to make enterprise JavaBeans here.

So that's part of what I see as the fun of trying to solve the whole problem. I do, in fact, care about solving the big scale problems, and I want to do that elegantly, and in a portable way, in an upgradable way. When Chris Thoburn was talking about universality falling out of just the desire for upgradeability - I think that's why you see that such themes about language specs, standards specifications, super-clear API boundaries coming out of this project is because we care so much about upgradability. All those things fall out as necessary, right?

We helped write the ES Modules spec because we knew we needed a stable way to express modules, that was going to be stable far into the future. So you needed a spec. And the same goes for promises. Promises \[unintelligible 01:17:13.23\] we helped write because everybody needs something like that. Let's try to agree. And so now - yeah, you don't have to go rewrite your promise implementations. That's how you get upgradability, is actually getting people to agree on what stuff means, in the interface sense, so that the implementations can evolve wildly over time.

**Chris Manson:** So just on this idea of upgradability... I think that's one of our key strengths in Ember. And I've seen it so many times where somebody is comparing these toy examples that Ed's talking about, and they spend two weeks on one framework, two weeks on another framework, two weeks on another framework, and they just compare what you can achieve. And in that game, Ember will lose 90% of the time, because it's more than you need, or it's clunky, or whatever the negative thing you want to put in there. But as soon as you cross a six-week boundary, and there's another minor release of Ember that you can upgrade with one command that not only changes your libraries, it also changes your blueprints in a way that keeps up to date, Ember starts winning. So you have this upgradeability that keeps you on the latest, that gives you new features for free in minor versions, and it's just not something that is done in the same way in other frameworks or communities.

**Chris Thoburn:** I think we're going to start winning on the early things, too... At least on the data side. The amount of things on my roadmap for the next year are big, but it's gonna take me a year.

**Kevin Ball:** Alright. So I want to wrap this up... Any last thoughts that you want to make sure make it out there for folks before we close?

**Edward Faulkner:** Sure, yeah. I could try to put a bow on the thoughts that we were sharing, and I was trying to riff off of what the other folks were saying... I think that if you care about building software to last, you come up with different choices than just kind of throwing something over the fence... And there's a time for the "throw something over the fence" thing if you're some agency that throws up a marketing website, and it's fixed budget, and you never come back to it again. Fine. Go use whatever, do whatever works for that. But if you care about building apps that last a long time, you get there by really getting a group of people to agree on what everything means; what the abstractions really mean, in a really crisp way. Even if the abstractions turn out to \[unintelligible 01:19:32.29\] Even to change an abstraction, you have to really get everybody to understand really what it means.

So there's a whole lot of communication outside of just the code, which is where a lot of the secret sauce is for longevity. So it's standards, it's docs, it's getting things upstreamed into the language or the next layer down of your spec. So I guess I'd say it's a human communication thing. That's really how you get it done. Semver is not for computers, it's for humans to talk to other humans, and that's just one example.

**Kevin Ball:** You're speaking my language right there. Well, and I will just throw one more thing out, that I'd love to see -- I feel like y'all have long been leading the community on things, and you talked about that, of thinking like a language designer \[unintelligible 01:20:16.01\] putting things... But what I'm loving to see in the current generation is you are not just leading by showing something and trying to get it into the spec, you're making the pieces that make Ember magical pluggable, so that other people can take those and plug with those. And I think that's another great way to be leading the community forward. So I'm very excited to see where this goes.

Awesome. Well, thank you, Chris, Ed and Chris... And I'm Kball. For all of you listening to JS Party, we'll catch you again next week.
