**Jerod Santo:**

What up, nerds? I'm Jerod and this is Changelog News for the week of Monday, February 10th, 2025.

We're gearing up to play some *Friendly Feud* (the new game show on Changelog & Friends that smells an awful lot like our old game show on JS Party) and we need your help!

Please take [our brand new survey](https://changelog.fm/feud) featuring all kinds of geeky questions. Find it at changelog.fm/feud. Once agiain that's changelog.fm/feud. It'll be fun PLUS you might win [a Changelog t-shirt](https://merch.changelog.com/products/the-changelog-shirt) for the effort!

Ok, let's get into this week's developer news worth your attention.

**Break:**

**Jerod Santo:**

[Tech is supposed to make our lives easier](https://www.youtube.com/watch?v=DifysK46DO4)

In the run-up to Super Bowl 59, Bill Maher dropped a "New Rule" segment excoriating the software industry and our relentless pursuit of change for change's sake. What does that have to do with the Super Bowl?

> Enjoy the Super Bowl this weekend while you can because it's probably one of the last ones to be shown on broadcast TV, which is a shame because streaming is ruining football and that's Taylor Swift's job.

Maher launches into a curse-laden tirade on what he calls Reverse Improvement (RI). The term is self-documenting, but he defines it anyway: "Making an upgrade to a popular product that nobody wants, needs or likes." Examples follow:

> When I get a notice that my phone needs an update it's like getting a jury duty summons. I just had one in my phone and now (for absolutely no reason or any sense of improvement) the process of seeing all my pictures: going to different albums, adding to albums, all of it; it's all different. So I have to relearn it, and now when I'm in an album all the photos in that album float by in a slideshow at the top. I didn't ask for that I don't want it and I don't and I don't want to have to go on a g** d***  expedition to find out how to turn it off!

The subjects of his ire, Silicon Valley nerds, of course:

> You like over engineering stuff but don't tell yourselves you're making anyone's life better. No one ever looked at a car and said, "If only the doors didn't have handles... What an improvement!"

He goes on, of course. (The entire 8:44 is worth your time. )

This should serve as a good reminder that our aim as software developers should always be on improvement, not merely change. If the technologies we invent don't actually make people's lives easier, what are we even doing?

**Break:**

**Jerod Santo:**

[How to thrive in a ChatGPT world](https://thebullshitmachines.com)

Two professors from the University of Washington put together a curriculum to help us manage the (already here, but not evenly distributed) new world where AI systems "saturate our information environment with bullshit at a scale we’ve never before encountered."

> For better or for worse, LLMs are here to stay. We all read content that they produce online, most of us interact with LLM chatbots, and many of us use them to produce content of our own.
>
> In a series of five- to ten-minute lessons, we will explain what these machines are, how they work, and how to thrive in a world where they are everywhere.

**Break:**

**Jerod Santo:**

[Chat is a bad UI pattern for dev tools](https://danieldelaney.net/chat/)

Daniel Delaney thinks deeply on a subject I've been pondering of late: the ideal language for specifying software requirements that meets the correct middle between humans and computers. Is it English? Is it Golang? Is it somewhere in between?

> AI was supposed to change everything. Finally, plain English could be a programming language—one everyone already knows. No syntax. No rules. Just say what you want.
>
> The first wave of AI coding tools squandered this opportunity. They make flashy demos but produce garbage software. People call them “great for prototyping,” which means “don’t use this for anything real.”

I don't have a solution to this problem yet, but Daniel and I agree on one thing: chat ain't it:

> Current AI tools pretend writing software is like having a conversation. It’s not. It’s like writing laws. You’re using English, but you’re defining terms, establishing rules, and managing complex interactions between everything you’ve said.
>
> This is the core problem. You can’t build real software without being precise about what you want. Every successful programming tool in history reflects this truth. AI briefly fooled us into thinking we could just chat our way to working software.
>
> We can’t. You don’t program by chatting. You program by writing documents.


**Break:**

**Jerod Santo:**

It's now time for Sponsored News!

[Six predictions for AI in 2025](https://www.augmentcode.com/blog/2025-ai-predictions)

"The rise of specialty models is coming", according to Augment Code CEO, Scott Dietzen.

He says:

> With DeepSeek and open source AIs closing the gap, concerns raised about LLM commoditization, advances in LLM reasoning, and questions about the future of the scaling laws... 2025 is shaping up to be a tumultuous year in AI. And it’s only February 😉.

Scott has some interesting takes from the front lines of AI tooling. His third prediction in the list of six is one you're likely to appreciate: **Coding AIs increase demand for software engineers**

Check out [the entire list of predictions](https://www.augmentcode.com/blog/2025-ai-predictions) and what the Augment Code team is doing about it at [augmentcode.com](https://augmentcode.com)

**Break:**

**Jerod Santo:**

[Are better models better?](https://www.ben-evans.com/benedictevans/2025/1/the-problem-with-better-models)

Benedict Evans:

> Every week there’s a better AI model that gives better answers. But a lot of questions don’t have better answers, only ‘right’ answers, and these models can’t do that. So what does ‘better’ mean, how do we manage these things, and should we change what we expect from computers?

Benedict's exploration into this topic is insightful and enlightening, comparing our plight with generative AI's inability to be always correct with the original iPod's inability to withstand being dropped on the ground. The common thread: shifting expectations.

> After 50 years of consumer computing, we have been trained to expect computers to be ‘right’ - to be predictable, deterministic systems... But if you flip that expectation, what do you get in return?

**Break:**

**Jerod Santo:**

[Reasons not to refactor](https://thoughtbot.com/blog/reasons-not-to-refactor)

I'm a big fan of refactoring. So much so that in many aspects of life I stop to ask myself, "how can I refactor this?"

But refactoring is not ALWAYS a good idea and our friends at Thoughtbot took some time to write down six cases when you actually shouldn't refactor a thing. I'll let you click through for the full list, but the first one is super important and easy to fall pray to, so I'll include it here for all to note: sometimes you only *think* you're refactoring...

> Many people use the word “refactoring” incorrectly. If we’re embarking on a change that is not really refactoring (for example looking at a bug or an adjustment after a third party change), we can’t fix it with refactoring.
>
> **What to do instead**: we need to think and talk about it differently from refactoring. We can stop and consider how the system will change (from what to what) and raise it with teammates to discuss why it matters, what action to take, and when.

**Break:**

**Jerod Santo:**

That's the news for now, but also scan the companion newsletter for even more news worth your attention, such as: Oracle defending their trademark by citing Node.js, Zach Holman on non-traditional red teams, and Redis Creator Antirez says we are destroying software.

Get in on the newsletter at changelog.com/news

We have some awesome episodes coming up this week: On Wednesday we're joined by Arun Gupta to talk about his new book: Fostering Open Source Culture. And on Friday, Jimmy Miller returns to talk discovery coding.

Have a great week! Leave us a 5-star review if you dig our work, and I'll talk to you again real soon.
